{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\programdata\\anaconda3\\lib\\site-packages (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.8.2)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (1.9.5)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1279 sha256=fa905c305e6ea5c41ff31824de9ecf8bf8db698e78c0b5a75c137cb71ca3572f\n",
      "  Stored in directory: c:\\users\\8b1d~1\\appdata\\local\\pip\\cache\\wheels\\0a\\9e\\ba\\20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2019.11.28)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import re\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://news.sarbc.ru/lenta/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая ищет ссылку на документ и краткое содержание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    dat = []\n",
    "    link = []\n",
    "    r = req.get(url)\n",
    "    soup=BeautifulSoup(r.content,\"lxml\")\n",
    "    for i, data in enumerate(soup.find_all('div', 'lenta-news-description')):\n",
    "        dat.append(re.sub('[\\n]','',data.text).strip(' '))\n",
    "        print(i/(2*len(soup.find_all('div', 'lenta-news-description'))))\n",
    "        clear_output(True)\n",
    "    for i,data in enumerate(soup.find_all(rel = 'nofollow', style=\"line-height: 150%;\")):\n",
    "        link.append(str(data)[8:str(data).find('rel')])\n",
    "        print(0.5 + i/(2*len(soup.find_all(rel = 'nofollow', style=\"line-height: 150%;\"))))\n",
    "        clear_output(True)\n",
    "    data = pd.DataFrame({'link':link, 'data':dat})\n",
    "    return data.drop(data[data['data'] == ''].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"http://www.rbc.ru/society/15/04/2020/5e96da1a...</td>\n",
       "      <td>В ведомстве заявили, что расследование в отнош...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"http://www.rbc.ru/society/15/04/2020/5e2fe945...</td>\n",
       "      <td>В России число зараженных коронавирусом превыс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"http://www.rbc.ru/society/15/04/2020/5e96d457...</td>\n",
       "      <td>Скопление людей в очередях перед входом в метр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"http://www.rbc.ru/economics/15/04/2020/5e96c3...</td>\n",
       "      <td>Глобальный спрос на нефть в апреле 2020 года у...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"http://www.rbc.ru/business/15/04/2020/5e96c16...</td>\n",
       "      <td>Российская нефть Urals подешевела, несмотря на...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>\"https://lenta.ru/news/2020/04/14/rezin/\"</td>\n",
       "      <td>В Москве владельцев двухкомнатной квартиры пос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>\"https://lenta.ru/news/2020/04/14/gpn/\"</td>\n",
       "      <td>Совместное предприятие «Газпром нефти» и Shell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>\"https://lenta.ru/news/2020/04/14/russia_usa/\"</td>\n",
       "      <td>Российский пловец, трехкратный призер чемпиона...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>\"https://lenta.ru/news/2020/04/14/sila/\"</td>\n",
       "      <td>В Краснодарском крае врачи силой укладывали кр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>\"https://lenta.ru/news/2020/04/14/darkphotons/\"</td>\n",
       "      <td>Китайские физики, работающие в коллаборации Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  link  \\\n",
       "0    \"http://www.rbc.ru/society/15/04/2020/5e96da1a...   \n",
       "1    \"http://www.rbc.ru/society/15/04/2020/5e2fe945...   \n",
       "2    \"http://www.rbc.ru/society/15/04/2020/5e96d457...   \n",
       "3    \"http://www.rbc.ru/economics/15/04/2020/5e96c3...   \n",
       "4    \"http://www.rbc.ru/business/15/04/2020/5e96c16...   \n",
       "..                                                 ...   \n",
       "208         \"https://lenta.ru/news/2020/04/14/rezin/\"    \n",
       "209           \"https://lenta.ru/news/2020/04/14/gpn/\"    \n",
       "210    \"https://lenta.ru/news/2020/04/14/russia_usa/\"    \n",
       "211          \"https://lenta.ru/news/2020/04/14/sila/\"    \n",
       "212   \"https://lenta.ru/news/2020/04/14/darkphotons/\"    \n",
       "\n",
       "                                                  data  \n",
       "0    В ведомстве заявили, что расследование в отнош...  \n",
       "1    В России число зараженных коронавирусом превыс...  \n",
       "2    Скопление людей в очередях перед входом в метр...  \n",
       "3    Глобальный спрос на нефть в апреле 2020 года у...  \n",
       "4    Российская нефть Urals подешевела, несмотря на...  \n",
       "..                                                 ...  \n",
       "208  В Москве владельцев двухкомнатной квартиры пос...  \n",
       "209  Совместное предприятие «Газпром нефти» и Shell...  \n",
       "210  Российский пловец, трехкратный призер чемпиона...  \n",
       "211  В Краснодарском крае врачи силой укладывали кр...  \n",
       "212  Китайские физики, работающие в коллаборации Ch...  \n",
       "\n",
       "[213 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarbc_data = get_data('https://news.sarbc.ru/lenta/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://svpressa.ru/all/news-archive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая ищет документ и краткое содержание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "\n",
    "\n",
    "def get_data_1(pages):\n",
    "    #Будем использовать библиотеку bs4 для парсинга\n",
    "    url = 'https://svpressa.ru/all/news-archive/'\n",
    "    r = req.get(url)\n",
    "    soup = BeautifulSoup(r.content.decode(\"utf-8\"))\n",
    "    data_short = []\n",
    "    data_full = []\n",
    "    #Каждый раз будем переходить на новую страницу новостей\n",
    "    for j in tqdm_notebook(range(pages)):\n",
    "        #Чтобы очищать RAM\n",
    "        if j%100 == 0:\n",
    "            df = pd.DataFrame({'data_full':data_full, 'data_short':data_short})\n",
    "            df.to_csv(\"/Users/александр/DLS deep learning school/Huawei_project/data/data\"+str(j/100)+\".csv\", index = False)\n",
    "            data_short = []\n",
    "            data_full = []\n",
    "        #Если новостей больше нет-останавливаемся\n",
    "        if soup.find_all('div', \"b-article__container_item\") == []:\n",
    "            break\n",
    "        #Находим специальные контейнеры в которых находятся новости\n",
    "        try:\n",
    "            for i in soup.find_all('div', \"b-article__container_item\"):\n",
    "                #Находим и преобразовываем краткое содержание\n",
    "                data_short.append(re.sub('\\xa0',' ',i.find('a', \"b-article__title b-article__title_item\").text))\n",
    "                #Ссылка на полную новость\n",
    "                link = str(i.find('a', \"b-article__title b-article__title_item\"))\n",
    "                link = 'https://svpressa.ru/{}/{}/{}'.format(*re.findall(r'\\w+', str(link))[7:10])\n",
    "                #Переходим по ссылке и преобразуем новость\n",
    "                z = BeautifulSoup(req.get(link).content)\\\n",
    "                .find('div', 'b-text__block b-text__block_text b-text__block_offset_large') \n",
    "                raw_text = [re.sub('\\xa0', ' ', piece.text) for piece in z.find_all('p')[:-2]]\n",
    "                data_full.append(raw_text) #попробовать поменять кодировку, чтобы не делать преобразований\n",
    "            #Обновляем страницу\n",
    "            page = str(soup.find_all('a', 'b-pages-nav__btn')[0])\n",
    "            page = page[page.find('href')+6:-12]\n",
    "            soup = BeautifulSoup(req.get(url + page).content.decode(\"utf-8\"))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16c535096a440dfa36fda5ca8b2d7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_data_1(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
